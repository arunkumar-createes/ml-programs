# pgm5
import seaborn as sns
import matplotlib.pyplot as plt

# Load the Iris dataset
iris = sns.load_dataset('iris')

# Scatter Plot: Sepal Length vs Sepal Width
plt.figure(figsize=(6, 4))
sns.scatterplot(data=iris, x='sepal_length', y='sepal_width', hue='species')
plt.title('Sepal Length vs Sepal Width')
plt.show()

# Bar Plot: Average Petal Length by Species
plt.figure(figsize=(6, 4))
sns.barplot(data=iris, x='species', y='petal_length', ci=None)
plt.title('Average Petal Length by Species')
plt.show()



#prgm 7
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
model = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)
y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred), "\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))



#pgrm8
from sklearn.datasets import make_regression
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

X, y = make_regression(n_samples=100, n_features=1, noise=10)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = LinearRegression().fit(X_train, y_train)
y_pred = model.predict(X_test)

print("MSE:", mean_squared_error(y_test, y_pred))
print("RÂ² Score:", r2_score(y_test, y_pred))


#9pgm
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

X, y = load_iris(return_X_y=True)
model = DecisionTreeClassifier().fit(X, y)

plt.figure(figsize=(10, 6))
plot_tree(model, filled=True)
plt.show()


#10pgm
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans

X, _ = make_blobs(n_samples=300, centers=4, random_state=0)
model = KMeans(n_clusters=4).fit(X)
labels = model.predict(X)

plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(*model.cluster_centers_.T, color='red', s=100, marker='X')
plt.title("K-Means Clustering"); plt.show()


#pgrm6
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Sample data
data = pd.DataFrame({'Age': [25, 30, None, 22], 'Gender': ['Male', 'Female', 'Female', None]})

data['Age'].fillna(data['Age'].mean(), inplace=True)  # Handle missing age
data['Gender'].fillna('Unknown', inplace=True)        # Handle missing gender

data['Gender'] = LabelEncoder().fit_transform(data['Gender'])  # Encode gender

scaled = StandardScaler().fit_transform(data)  # Feature scaling
print(pd.DataFrame(scaled, columns=['Age', 'Gender']))        
